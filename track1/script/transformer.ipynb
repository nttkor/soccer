{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e39ba4c",
   "metadata": {},
   "source": [
    "[Transformer 모델 설계]\n",
    "우리는 \"Encoder-Only Transformer\" (BERT 스타일) 구조를 사용할 것입니다.\n",
    "입력 (Input Sequence):\n",
    "모양: (Batch, Sequence_Length, Feature_Dim)\n",
    "Sequence_Length: 과거 10개의 이벤트 (LSTM보다 더 길게 봐도 됨)\n",
    "Feature_Dim: 스텝마다 [공 위치, 골대 정보, 액션ID, + 주변 선수들 정보]\n",
    "모델 구조:\n",
    "Embedding Layer: 좌표와 액션ID 등을 고차원 벡터로 변환\n",
    "Positional Encoding: 순서 정보 주입\n",
    "Transformer Encoder: Self-Attention을 통해 \"아, 3스텝 전의 패스가 중요했구나\"를 파악\n",
    "Output Head: 마지막 토큰의 정보를 받아서 (next_x, next_y) 예측\n",
    "[작업 순서]\n",
    "전처리: pre_test의 시퀀스 생성 로직을 가져오되, 주변 선수 정보도 포함시킵니다.\n",
    "모델링: PyTorch로 간단한 Transformer 클래스를 만듭니다.\n",
    "학습: GPU 서버(또는 로컬)에서 학습합니다. Transformer는 병렬 처리가 잘 돼서 LSTM보다 학습도 빠릅니다.\n",
    "바로 Transformer 모델 코드를 짜드릴까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7438efc",
   "metadata": {},
   "source": [
    "이 코드는 다음 단계로 구성됩니다:\n",
    "데이터 전처리: 전체 데이터를 로드하고, 각 에피소드별로 시퀀스 데이터(Sequence Data)를 만듭니다. 피처에는 [x, y, 골대거리, 골대각도, 액션ID]를 포함합니다. (주변 선수 정보는 일단 데이터가 무거워질 수 있으니, 1차적으로 가벼운 버전으로 먼저 성능을 봅니다.)\n",
    "Transformer 모델 정의: PyTorch의 nn.TransformerEncoder를 사용하여 시계열 패턴을 학습하는 모델을 만듭니다.\n",
    "학습 및 추론: 모델을 학습시키고, test.csv에 대한 제출 파일을 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e3eb8",
   "metadata": {},
   "source": [
    "## [현재 모델링 진행 상황 요약]\n",
    "\n",
    "### 1. 데이터 엔지니어링\n",
    "- **피처 확장 (8차원)**: 기존 [x, y, 거리, 각도, action]에 추가로:\n",
    "  - **속도(Velocity)**: [vx, vy] (이전 스텝과의 좌표 차이)\n",
    "  - **결과(Result)**: Successful(1), Unsuccessful(-1), Others(0) (성공/실패 여부를 힌트로 제공)\n",
    "- **데이터 증강 (Data Augmentation)**: 학습 데이터 4배 확대\n",
    "  - 원본 + 상하반전 + 좌우반전 + 상하좌우반전\n",
    "  - **순서 보장**: 시계열 흐름이 끊기지 않도록 [원본전체] -> [증강전체] 순으로 배치\n",
    "\n",
    "### 2. 모델 구조 (Transformer Encoder)\n",
    "- **입력**: (Batch, Seq_Len=10, Feature=8)\n",
    "- **Hyperparams**: d_model=256, nhead=8, layers=3, dropout=0.2\n",
    "- **출력**: 마지막 시점의 (x, y) 좌표 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db04517",
   "metadata": {},
   "source": [
    "네, 죄송합니다. 마크다운 내용을 아래에 제공해 드리겠습니다. 복사해서 **3번 셀(제목 있는 곳)**에 붙여넣으시면 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### [코드 실행 순서 및 개요]\n",
    "\n",
    "이 노트북은 축구 경기 데이터를 사용하여 **Transformer 기반의 다음 좌표 예측 모델**을 학습하고 추론하는 과정을 담고 있습니다.\n",
    "\n",
    "### 1. 환경 설정 및 데이터 로드\n",
    "- **라이브러리**: PyTorch, Pandas, Numpy 등 필수 패키지 임포트\n",
    "- **데이터 로드**: `train.csv`를 읽어옵니다.\n",
    "- **정규화**: 좌표(105x68)와 Action ID를 0~1 범위로 스케일링합니다.\n",
    "- **결과 매핑**: `result_name`을 수치화합니다 (성공=1, 실패=-1, 기타=0).\n",
    "- **데이터 분할**: **Data Leakage 방지**를 위해 `game_episode` 단위로 학습/검증 데이터를 나눕니다.\n",
    "\n",
    "### 2. 데이터셋 구축 (Feature Engineering & Augmentation)\n",
    "- **시퀀스 생성**: 각 에피소드에서 과거 **10개**의 이벤트를 묶어 하나의 입력 시퀀스로 만듭니다.\n",
    "- **피처 확장 (8차원)**:\n",
    "  1. `x`, `y` (좌표)\n",
    "  2. `distance` (골대까지 거리)\n",
    "  3. `angle` (골대까지 각도)\n",
    "  4. `action_id` (행동 종류)\n",
    "  5. `vx`, `vy` (**속도**: 이전 스텝과의 차이)\n",
    "  6. `result` (**결과**: 성공/실패 여부)\n",
    "- **데이터 증강 (학습셋만 적용)**: 데이터 양을 **4배**로 늘립니다.\n",
    "  1. 원본 데이터\n",
    "  2. 상하 반전 (y축 대칭)\n",
    "  3. 좌우 반전 (x축 대칭)\n",
    "  4. 상하좌우 반전 (점 대칭)\n",
    "\n",
    "### 3. 모델 정의 (SoccerTransformer)\n",
    "- **구조**: Encoder-Only Transformer (BERT 스타일)\n",
    "- **Embedding**: 8차원 피처 -> 256차원 벡터\n",
    "- **Positional Encoding**: 시계열 순서 정보 주입\n",
    "- **Encoder Layers**: 3층의 Self-Attention 레이어 (Head=8)\n",
    "- **Output Head**: 마지막 시점의 벡터를 받아 (x, y) 좌표 예측\n",
    "\n",
    "### 4. 학습 (Training Loop)\n",
    "- **Optimizer**: Adam (lr=0.0005)\n",
    "- **Scheduler**: ReduceLROnPlateau (검증 성능 정체 시 학습률 감소)\n",
    "- **Process**: 100 Epoch 동안 학습하며, 매 Epoch마다 검증셋으로 성능(거리 오차)을 평가합니다.\n",
    "\n",
    "### 5. 추론 및 제출 (Inference)\n",
    "- `test.csv`의 경로를 통해 테스트 데이터를 로드합니다.\n",
    "- 학습과 동일한 전처리(정규화, 피처 생성)를 거칩니다.\n",
    "- 학습된 모델로 다음 좌표를 예측하고, 원래 크기(105x68)로 복원하여 제출 파일(`submission.csv`)을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4828df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중...\n",
      "학습 에피소드: 12348개, 검증 에피소드: 3087개\n",
      "학습 데이터셋 생성 중 (4배 증강 적용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "시퀀스 생성(Augment=True): 100%|██████████| 12348/12348 [00:09<00:00, 1240.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Shape: (49392, 10, 8)\n",
      "검증 데이터셋 생성 중 (증강 미적용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "시퀀스 생성(Augment=False): 100%|██████████| 3087/3087 [00:02<00:00, 1524.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 Shape: (3087, 10, 8)\n",
      "Using Device: cuda\n",
      "SoccerTransformer(\n",
      "  (embedding): Linear(in_features=8, out_features=256, bias=True)\n",
      "  (pos_encoder): PositionalEncoding()\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc_out): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "[Transformer 학습 시작]\n",
      "Epoch 05 | Loss: 0.04096 | Val Score: 17.4767 | LR: 5.00e-04 | Time: 15.6s\n",
      "Epoch 10 | Loss: 0.03828 | Val Score: 18.1358 | LR: 5.00e-04 | Time: 15.0s\n",
      "Epoch 15 | Loss: 0.03722 | Val Score: 18.1293 | LR: 5.00e-04 | Time: 15.9s\n",
      "Epoch 20 | Loss: 0.03440 | Val Score: 17.0425 | LR: 2.50e-04 | Time: 15.8s\n",
      "Epoch 25 | Loss: 0.03336 | Val Score: 17.0505 | LR: 2.50e-04 | Time: 15.9s\n",
      "Epoch 30 | Loss: 0.03163 | Val Score: 16.8196 | LR: 1.25e-04 | Time: 15.6s\n",
      "Epoch 35 | Loss: 0.03063 | Val Score: 17.1601 | LR: 6.25e-05 | Time: 16.1s\n",
      "Epoch 40 | Loss: 0.02954 | Val Score: 16.9566 | LR: 6.25e-05 | Time: 16.1s\n",
      "Epoch 45 | Loss: 0.02868 | Val Score: 16.4549 | LR: 3.13e-05 | Time: 15.6s\n",
      "Epoch 50 | Loss: 0.02855 | Val Score: 16.5576 | LR: 3.13e-05 | Time: 15.7s\n",
      "Epoch 55 | Loss: 0.02802 | Val Score: 16.5425 | LR: 1.56e-05 | Time: 15.8s\n",
      "Epoch 60 | Loss: 0.02781 | Val Score: 16.5174 | LR: 7.81e-06 | Time: 15.3s\n",
      "Epoch 65 | Loss: 0.02769 | Val Score: 16.5162 | LR: 3.91e-06 | Time: 16.0s\n",
      "Epoch 70 | Loss: 0.02760 | Val Score: 16.5727 | LR: 1.95e-06 | Time: 16.0s\n",
      "Epoch 75 | Loss: 0.02761 | Val Score: 16.5547 | LR: 9.77e-07 | Time: 15.8s\n",
      "Epoch 80 | Loss: 0.02756 | Val Score: 16.5562 | LR: 9.77e-07 | Time: 15.8s\n",
      "Epoch 85 | Loss: 0.02757 | Val Score: 16.5702 | LR: 4.88e-07 | Time: 15.2s\n",
      "Epoch 90 | Loss: 0.02753 | Val Score: 16.5637 | LR: 2.44e-07 | Time: 15.3s\n",
      "Epoch 95 | Loss: 0.02746 | Val Score: 16.5787 | LR: 1.22e-07 | Time: 15.3s\n",
      "Epoch 100 | Loss: 0.02757 | Val Score: 16.5712 | LR: 6.10e-08 | Time: 14.8s\n",
      "[추론 시작]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2414/2414 [00:11<00:00, 214.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료: submission_transformer_v5_result_feat1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# [축구 경기 예측을 위한 Transformer 모델링 스크립트]\n",
    "# - 작업: 데이터 로드, 전처리(피처 엔지니어링, 증강), 모델 정의, 학습, 추론\n",
    "# - 특징: 8차원 피처(좌표, 속도, 결과 등), 4배 데이터 증강, Transformer Encoder 구조\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "CONFIG = {\n",
    "    \"field_dims\": (105.0, 68.0),\n",
    "    \"action_scale\": 60.0,\n",
    "    \"goal_xy\": (1.0, 0.5),\n",
    "    \"seq_len\": 10,\n",
    "    \"feature_size\": 8,\n",
    "    \"augmentations\": {\n",
    "        \"vertical\": True,\n",
    "        \"horizontal\": True,\n",
    "        \"both\": True,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"d_model\": 256,\n",
    "        \"nhead\": 8,\n",
    "        \"num_layers\": 3,\n",
    "        \"dropout\": 0.2,\n",
    "        \"lr\": 5e-4,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 64,\n",
    "        \"log_interval\": 5,\n",
    "    },\n",
    "    \"fallback_xy\": (52.5, 34.0),\n",
    "}\n",
    "\n",
    "\n",
    "def map_result(value):\n",
    "    \"\"\"Map textual result labels to numeric hints.\"\"\"\n",
    "    if value == 'Successful':\n",
    "        return 1.0\n",
    "    if value == 'Unsuccessful':\n",
    "        return -1.0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, config, is_train=True):\n",
    "    \"\"\"Normalize coordinates/action id and attach numeric result column.\"\"\"\n",
    "    field_x, field_y = config[\"field_dims\"]\n",
    "    df = df.copy()\n",
    "    for col in (\"start_x\", \"end_x\"):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float) / field_x\n",
    "    for col in (\"start_y\", \"end_y\"):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float) / field_y\n",
    "    if \"action_id\" in df.columns:\n",
    "        df[\"action_id\"] = df[\"action_id\"].fillna(0) / config[\"action_scale\"]\n",
    "    else:\n",
    "        df[\"action_id\"] = 0.0\n",
    "    if \"result_name\" in df.columns:\n",
    "        df[\"result_mapped\"] = df[\"result_name\"].apply(map_result)\n",
    "    elif \"result_mapped\" not in df.columns:\n",
    "        df[\"result_mapped\"] = 0.0\n",
    "    else:\n",
    "        df[\"result_mapped\"] = df[\"result_mapped\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_feature_matrix(coords, actions, results, goal_xy):\n",
    "    \"\"\"Compose the 8D feature matrix for a single episode.\"\"\"\n",
    "    goal_x, goal_y = goal_xy\n",
    "    dist = np.sqrt((coords[:, 0] - goal_x) ** 2 + (coords[:, 1] - goal_y) ** 2).reshape(-1, 1)\n",
    "    angle = np.arctan2(coords[:, 1] - goal_y, coords[:, 0] - goal_x).reshape(-1, 1)\n",
    "    velocities = np.zeros_like(coords)\n",
    "    if len(coords) > 1:\n",
    "        velocities[1:, 0] = coords[1:, 0] - coords[:-1, 0]\n",
    "        velocities[1:, 1] = coords[1:, 1] - coords[:-1, 1]\n",
    "    return np.hstack([coords, dist, angle, actions, velocities, results])\n",
    "\n",
    "\n",
    "def pad_or_truncate(feats, seq_len, feature_size):\n",
    "    \"\"\"Match sequence length by trimming old steps or front-padding zeros.\"\"\"\n",
    "    if len(feats) >= seq_len:\n",
    "        return feats[-seq_len:]\n",
    "    padded = np.zeros((seq_len, feature_size))\n",
    "    padded[-len(feats):] = feats\n",
    "    return padded\n",
    "\n",
    "\n",
    "def generate_variants(coords, target, config, enable_augment):\n",
    "    \"\"\"Create augmented coordinate/target pairs according to config.\"\"\"\n",
    "    variants = [(coords, target)]\n",
    "    if not enable_augment:\n",
    "        return variants\n",
    "    aug_cfg = config[\"augmentations\"]\n",
    "    if aug_cfg.get(\"vertical\"):\n",
    "        coords_v = coords.copy()\n",
    "        coords_v[:, 1] = 1.0 - coords_v[:, 1]\n",
    "        target_v = target.copy()\n",
    "        target_v[1] = 1.0 - target_v[1]\n",
    "        variants.append((coords_v, target_v))\n",
    "    if aug_cfg.get(\"horizontal\"):\n",
    "        coords_h = coords.copy()\n",
    "        coords_h[:, 0] = 1.0 - coords_h[:, 0]\n",
    "        target_h = target.copy()\n",
    "        target_h[0] = 1.0 - target_h[0]\n",
    "        variants.append((coords_h, target_h))\n",
    "    if aug_cfg.get(\"both\"):\n",
    "        coords_hv = coords.copy()\n",
    "        coords_hv[:, 0] = 1.0 - coords_hv[:, 0]\n",
    "        coords_hv[:, 1] = 1.0 - coords_hv[:, 1]\n",
    "        target_hv = target.copy()\n",
    "        target_hv[0] = 1.0 - target_hv[0]\n",
    "        target_hv[1] = 1.0 - target_hv[1]\n",
    "        variants.append((coords_hv, target_hv))\n",
    "    return variants\n",
    "\n",
    "\n",
    "def create_sequences(df, config, augment=False):\n",
    "    \"\"\"Convert an entire dataframe into stacked sequences and targets.\"\"\"\n",
    "    sequences, targets = [], []\n",
    "    seq_len = config[\"seq_len\"]\n",
    "    feature_size = config[\"feature_size\"]\n",
    "    grouped = df.groupby('game_episode')\n",
    "    for _, group in tqdm(grouped, desc=f\"시퀀스 생성(Augment={augment})\"):\n",
    "        group = group.sort_values('time_seconds')\n",
    "        coords = group[['start_x', 'start_y']].values\n",
    "        actions = group['action_id'].values.reshape(-1, 1)\n",
    "        results = group['result_mapped'].values.reshape(-1, 1)\n",
    "        target = group[['end_x', 'end_y']].values[-1].copy()\n",
    "        for coords_variant, target_variant in generate_variants(coords, target, config, augment):\n",
    "            feats = build_feature_matrix(coords_variant, actions, results, config['goal_xy'])\n",
    "            seq = pad_or_truncate(feats, seq_len, feature_size)\n",
    "            sequences.append(seq)\n",
    "            targets.append(target_variant)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n",
    "def load_match_sequence(file_path, config):\n",
    "    \"\"\"Load and preprocess a single match csv into a padded sequence.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    temp_df = pd.read_csv(file_path)\n",
    "    temp_df = preprocess_dataframe(temp_df, config, is_train=False)\n",
    "    coords = temp_df[['start_x', 'start_y']].values\n",
    "    actions = temp_df['action_id'].values.reshape(-1, 1)\n",
    "    results = temp_df['result_mapped'].values.reshape(-1, 1)\n",
    "    feats = build_feature_matrix(coords, actions, results, config['goal_xy'])\n",
    "    return pad_or_truncate(feats, config['seq_len'], config['feature_size'])\n",
    "\n",
    "\n",
    "def run_inference(model, meta_df, base_path, config, device):\n",
    "    \"\"\"Iterate over metadata rows and generate predictions.\"\"\"\n",
    "    model.eval()\n",
    "    preds_x, preds_y = [], []\n",
    "    fallback_x, fallback_y = config['fallback_xy']\n",
    "    with torch.no_grad():\n",
    "        for _, row in tqdm(meta_df.iterrows(), total=len(meta_df)):\n",
    "            file_path = os.path.join(base_path, row['path'][2:])\n",
    "            seq = load_match_sequence(file_path, config)\n",
    "            if seq is None:\n",
    "                preds_x.append(fallback_x)\n",
    "                preds_y.append(fallback_y)\n",
    "                continue\n",
    "            input_tensor = torch.FloatTensor(seq).unsqueeze(0).to(device)\n",
    "            pred = model(input_tensor).cpu().numpy()[0]\n",
    "            preds_x.append(pred[0] * config['field_dims'][0])\n",
    "            preds_y.append(pred[1] * config['field_dims'][1])\n",
    "    return preds_x, preds_y\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        length = x.size(1)\n",
    "        return x + self.pe[:, :length, :]\n",
    "\n",
    "\n",
    "class SoccerTransformer(nn.Module):\n",
    "    \"\"\"Encoder-only Transformer tailored for soccer sequence regression.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        model_cfg = config['model']\n",
    "        feature_size = config['feature_size']\n",
    "        self.embedding = nn.Linear(feature_size, model_cfg['d_model'])\n",
    "        self.pos_encoder = PositionalEncoding(model_cfg['d_model'])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_cfg['d_model'],\n",
    "            nhead=model_cfg['nhead'],\n",
    "            dim_feedforward=512,\n",
    "            dropout=model_cfg['dropout'],\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=model_cfg['num_layers'])\n",
    "        self.fc_out = nn.Linear(model_cfg['d_model'], 2)\n",
    "\n",
    "    def forward(self, src):\n",
    "        x = self.embedding(src)\n",
    "        x = self.pos_encoder(x)\n",
    "        encoded = self.transformer_encoder(x)\n",
    "        return self.fc_out(encoded[:, -1, :])\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, val_inputs, val_targets, criterion, device, field_dims):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(val_inputs)\n",
    "        loss = criterion(outputs, val_targets).item()\n",
    "        diff_x = (outputs[:, 0] - val_targets[:, 0]) * field_dims[0]\n",
    "        diff_y = (outputs[:, 1] - val_targets[:, 1]) * field_dims[1]\n",
    "        val_score = torch.mean(torch.sqrt(diff_x ** 2 + diff_y ** 2)).item()\n",
    "    return loss, val_score\n",
    "\n",
    "\n",
    "print(\"데이터 로드 중...\")\n",
    "train_df = pd.read_csv(\"../open_track1/train.csv\")\n",
    "train_df = preprocess_dataframe(train_df, CONFIG, is_train=True)\n",
    "unique_episodes = train_df['game_episode'].unique()\n",
    "train_episodes, val_episodes = train_test_split(unique_episodes, test_size=0.2, random_state=42)\n",
    "train_df_split = train_df[train_df['game_episode'].isin(train_episodes)].copy()\n",
    "val_df_split = train_df[train_df['game_episode'].isin(val_episodes)].copy()\n",
    "print(f\"학습 에피소드: {len(train_episodes)}개, 검증 에피소드: {len(val_episodes)}개\")\n",
    "\n",
    "print(\"학습 데이터셋 생성 중 (4배 증강 적용)...\")\n",
    "X_train, y_train = create_sequences(train_df_split, CONFIG, augment=True)\n",
    "print(f\"학습 데이터 Shape: {X_train.shape}\")\n",
    "print(\"검증 데이터셋 생성 중 (증강 미적용)...\")\n",
    "X_val, y_val = create_sequences(val_df_split, CONFIG, augment=False)\n",
    "print(f\"검증 데이터 Shape: {X_val.shape}\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train)),\n",
    "    batch_size=CONFIG['training']['batch_size'],\n",
    "    shuffle=True,\n",
    ")\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "model = SoccerTransformer(CONFIG).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['model']['lr'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "print(model)\n",
    "\n",
    "print(\"[Transformer 학습 시작]\")\n",
    "training_cfg = CONFIG['training']\n",
    "X_val_tensor = X_val_tensor.to(device)\n",
    "y_val_tensor = y_val_tensor.to(device)\n",
    "for epoch in range(training_cfg['epochs']):\n",
    "    start = time()\n",
    "    avg_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_score = evaluate(model, X_val_tensor, y_val_tensor, criterion, device, CONFIG['field_dims'])\n",
    "    scheduler.step(val_loss)\n",
    "    if (epoch + 1) % training_cfg['log_interval'] == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        elapsed = time() - start\n",
    "        print(f\"Epoch {epoch+1:02d} | Loss: {avg_loss:.5f} | Val Score: {val_score:.4f} | LR: {current_lr:.2e} | Time: {elapsed:.1f}s\")\n",
    "\n",
    "print(\"[추론 시작]\")\n",
    "test_meta = pd.read_csv(\"../open_track1/test.csv\")\n",
    "preds_x, preds_y = run_inference(model, test_meta, \"../open_track1\", CONFIG, device)\n",
    "\n",
    "submission = pd.read_csv(\"../open_track1/sample_submission.csv\")\n",
    "submission['end_x'] = preds_x\n",
    "submission['end_y'] = preds_y\n",
    "output_name = \"submission_transformer_v5_result_feat1.csv\"\n",
    "submission.to_csv(output_name, index=False)\n",
    "print(f\"저장 완료: {output_name}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
